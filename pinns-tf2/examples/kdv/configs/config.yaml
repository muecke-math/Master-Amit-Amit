defaults:
  - train
  - _self_

idx_t0: 40
idx_t1: 160
idx_t_test: 190 # Added for testing
N0: 199
N1: 201
q: 50
discrete: True

time_domain:
  _target_: pinnstf2.data.TimeDomain
  t_interval: [0, 1]
  t_points: 201

spatial_domain:
  _target_: pinnstf2.data.Interval
  x_interval: [-1, 1]
  shape: [512, 1]

mesh:
  _target_: pinnstf2.data.Mesh
  root_dir: ${paths.data_dir}
  read_data_fn: ???

runge_kutta:
  _target_: pinnstf2.models.RungeKutta
  root_dir: ${paths.rk_dir}
  q: ${q}
  t1: ${idx_t0}
  t2: ${idx_t1}
  time_domain: ${time_domain}

train_datasets:
  - mesh_sampler:
      _target_: pinnstf2.data.DiscreteMeshSampler
      _partial_: true
      num_sample: ${N0}
      idx_t: ${idx_t0}
      solution:
        - u
      collection_points:
        - f

  - mesh_sampler:
      _target_: pinnstf2.data.DiscreteMeshSampler
      _partial_: true
      num_sample: ${N1}
      idx_t: ${idx_t1}
      solution:
        - u
      collection_points:
        - f

val_dataset:
  - mesh_sampler:
      _target_: pinnstf2.data.DiscreteMeshSampler
      _partial_: true
      idx_t: ${idx_t1}
      solution:
        - u

# Now the test dataset uses a different time index (idx_t_test)
test_dataset:
  - mesh_sampler:
      _target_: pinnstf2.data.DiscreteMeshSampler
      _partial_: true
      idx_t: ${idx_t_test}
      solution:
        - u

pred_dataset:
  - mesh_sampler:
      _target_: pinnstf2.data.DiscreteMeshSampler
      _partial_: true
      idx_t: ${idx_t1}
      solution:
        - u

net:
  _target_: pinnstf2.models.FCN
  layers:
    - 1
    - 50
    - 50
    - 50
    - 50 # Added extra layer
    - ${q}
  output_names:
    - u
  discrete: ${discrete}
  activation: "tanh"  # or "tanh" YY, "sigmoid" YY, "relu" XX, "swish" YY, "softsign" XX, "softplus" YY.

model:
  optimizer: ${optimizer}
  loss_fn: sse # sse (default) , mse, mae, huber.
  runge_kutta: ${runge_kutta}
  extra_variables:
    l1: 0.0
    l2: -6.0

# Optimizer configuration provided
optimizer:
  _target_: tensorflow.keras.optimizers.Adam
  learning_rate: 0.001
# optimizer:
#   _target_: tensorflow.keras.optimizers.Adagrad
#   learning_rate: 0.01
#   initial_accumulator_value: 0.1
# optimizer:
#   _target_: tensorflow.keras.optimizers.RMSprop
#   learning_rate: 0.001
#   rho: 0.9
#   momentum: 0.0
#   epsilon: 1e-7
# optimizer:
#   _target_: tensorflow.keras.optimizers.Nadam
#   learning_rate: 0.002
#   beta_1: 0.9
#   beta_2: 0.999
#   epsilon: 1e-7

trainer:
  max_epochs: 50000
  check_val_every_n_epoch: 50001
  default_root_dir: ${tensorboard.log_dir}  # Pass log directory to enable Trainer's TensorBoard.

train: true
val: true
test: true
optimized_metric:
  error:
    - u
  test: # Comment it out if you dont want test
    - u
  extra_variables:
    - l1
    - l2

plotting:
  _target_: pinnstf2.utils.plot_kdv
  _partial_: true

task_name: kdv

hydra:
  searchpath:
    - pkg://pinnstf2/conf

tensorboard:
  log_dir: ${paths.output_dir}/logs
  histogram_freq: 1
  write_graph: true
  update_freq: epoch